{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text Classification_Word2Vec_Logistic Regression_Naive Bayes.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM8xmvGmXNuxaDFZcxe/YZJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shruti1102000/Text-Classification2-using-Word2Vec-Logistic-Regression-and-Naive-Bayes/blob/main/Text_Classification_Word2Vec_Logistic_Regression_Naive_Bayes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQafRu6QHoEt"
      },
      "source": [
        "#Importing all the necessary Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "d__VbUZ86Ibg",
        "outputId": "dd668d28-5311-4758-e1fd-94f3b82266af"
      },
      "source": [
        "from nltk.corpus import reuters \n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "import pandas as pd\n",
        "import spacy\n",
        "import numpy as np\n",
        "\n",
        "'''\n",
        "  https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html\n",
        "  https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
        "  https://spacy.io/usage/vectors-similarity\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n  https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html\\n  https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\\n  https://spacy.io/usage/vectors-similarity\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qCclui986MWZ",
        "outputId": "2fd3a656-d933-43f3-fe5d-4a474ebef0b6"
      },
      "source": [
        "import nltk\n",
        "nltk.download('reuters')\n",
        "!python -m spacy download en_core_web_lg"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package reuters to /root/nltk_data...\n",
            "Collecting en_core_web_lg==2.2.5\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.2.5/en_core_web_lg-2.2.5.tar.gz (827.9MB)\n",
            "\u001b[K     |████████████████████████████████| 827.9MB 1.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_lg==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (0.8.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (51.1.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.3.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.7.4.3)\n",
            "Building wheels for collected packages: en-core-web-lg\n",
            "  Building wheel for en-core-web-lg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for en-core-web-lg: filename=en_core_web_lg-2.2.5-cp36-none-any.whl size=829180945 sha256=b3416128368a29e8f70b23165e437436b7986684f94e88b43ae22b4c885cefae\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-1qi_6c0p/wheels/2a/c1/a6/fc7a877b1efca9bc6a089d6f506f16d3868408f9ff89f8dbfc\n",
            "Successfully built en-core-web-lg\n",
            "Installing collected packages: en-core-web-lg\n",
            "Successfully installed en-core-web-lg-2.2.5\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_lg')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "znaFDj4E6RFe",
        "outputId": "cae9b21d-9c82-4d10-dd0d-df30fd338886"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mf3WWxx17hdy",
        "outputId": "a6a783f7-cf03-4284-d1ab-87b8f746e4ef"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8RH6pLJLHzFE"
      },
      "source": [
        "#Loading data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYExDYbM7l4r"
      },
      "source": [
        "mlb = MultiLabelBinarizer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibX5x_1o73N9"
      },
      "source": [
        "def collection_stats():\n",
        "  documents = reuters.fileids()\n",
        "  print(str(len(documents)) + \" documents\");\n",
        "\n",
        "  train_docs = list(filter(lambda doc: doc.startswith(\"train\"), documents));\n",
        "  print(str(len(train_docs)) + \" total train documents\");\n",
        " \n",
        "  test_docs = list(filter(lambda doc: doc.startswith(\"test\"), documents));\n",
        "  print(str(len(test_docs)) + \" total test documents\")\n",
        "\n",
        "  categories = reuters.categories()\n",
        "\n",
        "  print(str(len(categories)) + \" categories\");"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_BvYGfi08ucz",
        "outputId": "650ad7eb-507e-412c-d917-e1a3cb5e3f13"
      },
      "source": [
        "collection_stats()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10788 documents\n",
            "7769 total train documents\n",
            "3019 total test documents\n",
            "90 categories\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ie3sVw9NH6KL"
      },
      "source": [
        "#Train Test Split of Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDwPWhNc8xmS"
      },
      "source": [
        "def train_test_split():\n",
        "  documents = reuters.fileids()\n",
        "  train_docs = [document for document in documents if document.startswith(\"train\")]\n",
        "  test_docs = [document for document in documents if document.startswith(\"test\")]\n",
        "  x_train = [reuters.raw(doc_id) for doc_id in train_docs]\n",
        "  y_train = [reuters.raw(doc_id) for doc_id in test_docs]\n",
        "  x_test = mlb.fit_transform([reuters.categories(doc_id) for doc_id in train_docs])\n",
        "  y_test = mlb.transform([reuters.categories(doc_id) for doc_id in test_docs])\n",
        "  return x_train, y_train, x_test, y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhQk-xbX82LU"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SkNRI_cfIBGi"
      },
      "source": [
        "#Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qePLNQg84ou"
      },
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9FSWs-p9Ade"
      },
      "source": [
        "stop_words = set(stopwords.words('english'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3zI76CD9Oxk"
      },
      "source": [
        "def clean_text(X_train):\n",
        "  \"\"\" function to clean data , input should a list of data like list of training data or test data and it will return cleaned data\"\"\"\n",
        "  ret=[]\n",
        "  for x_pre in X_train:\n",
        "    #Used for removing url\n",
        "    x_pre = re.sub(r'http\\S+','',x_pre)\n",
        "    #Punctuation used\n",
        "    x_pre = re.sub('[^a-zA-Z]',' ',x_pre)\n",
        "    x_pre = str(x_pre).lower()\n",
        "    x_pre = word_tokenize(x_pre)\n",
        "    x_pre = [item for item in x_pre if item not in stop_words]\n",
        "    x_pre = ' '.join(x_pre)\n",
        "    ret.append(x_pre)\n",
        "  return ret"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAtFZg2m9UIR"
      },
      "source": [
        "X_train=clean_text(x_train)\n",
        "X_test =clean_text(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVxMarNgFJ8i"
      },
      "source": [
        "#Word2Vec Representation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffMtgpRt9XBe"
      },
      "source": [
        "nlp = spacy.load(\"en_core_web_lg\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3elpgHx19abZ"
      },
      "source": [
        "def get_word_vectors(sentence):\n",
        "  \"\"\" Function to get vector representations for the input sentence \"\"\"\n",
        "  tokens = nlp(sentence)\n",
        "  vector = np.sum([token.vector for token in tokens], axis=0)\n",
        "  return vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "baoccqAm_ZQB",
        "outputId": "568146d8-57c5-4227-a324-dd60444da529"
      },
      "source": [
        "get_word_vectors(X_train[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-2.75820847e+01,  4.80285072e+01,  2.63230686e+01, -1.69591427e+01,\n",
              "        1.80133934e+01, -2.24143391e+01,  1.48427067e+01, -1.22261572e+01,\n",
              "        1.42772484e+01,  3.79833740e+02, -7.19789963e+01,  6.65385580e+00,\n",
              "        9.59873021e-01, -2.29884491e+01, -1.52617760e+01, -3.18562469e+01,\n",
              "       -1.64772568e+01,  2.46751480e+02,  2.48471332e+00,  4.81173801e+00,\n",
              "        2.88610244e+00,  4.07470245e+01,  1.53115969e+01, -8.51059628e+00,\n",
              "       -1.46224194e+01, -5.99359155e-01, -4.22670250e+01, -1.40666113e+01,\n",
              "       -1.54306364e+01,  1.24010420e+01, -2.35580215e+01, -2.49290314e+01,\n",
              "        4.47599182e+01,  1.93292503e+01, -3.67137413e+01,  2.17424774e+01,\n",
              "       -1.57869434e+00, -5.76404476e+00,  7.08951378e+00, -1.90575714e+01,\n",
              "       -1.16823959e+01, -2.75175929e+00,  4.03215637e+01, -8.44150734e+00,\n",
              "       -1.14671640e+01,  1.71466293e+01,  1.40707121e+01, -1.82018433e+01,\n",
              "       -3.23085475e+00,  2.57947311e+01, -9.70202637e+00, -2.38714981e+01,\n",
              "        2.18323278e+00, -4.48880863e+00,  3.96375923e+01, -2.55769920e+01,\n",
              "       -2.62335491e+00,  3.49515724e+00,  1.63950086e+00, -1.69699860e+01,\n",
              "       -2.23401241e+01, -3.17762394e+01, -1.53890276e+01,  2.03449783e+01,\n",
              "        5.49853468e+00, -1.31475191e+01, -2.15081902e+01,  1.98841953e+01,\n",
              "       -1.71637821e+01,  1.88987122e+01, -4.29925537e+00,  2.86040611e+01,\n",
              "        1.11729183e+01, -3.06283808e+00,  4.84139900e+01,  2.82470303e+01,\n",
              "        3.58648987e+01,  4.27802925e+01,  1.47919245e+01,  1.87794189e+01,\n",
              "        4.76667252e+01,  6.07616501e+01,  8.93951702e+00,  1.02134590e+01,\n",
              "       -2.09814854e+01, -1.11504288e+01,  9.60222015e+01,  1.50383453e+01,\n",
              "        2.89311676e+01,  3.09763670e+00,  2.16637821e+01, -4.03105278e+01,\n",
              "       -2.64259052e+00, -4.23018875e+01, -1.25686111e+01, -5.31816816e+00,\n",
              "        3.53761902e+01,  1.06566467e+01,  1.70059414e+01,  1.68328209e+01,\n",
              "       -2.49928894e+01, -8.45480156e+00, -3.46916733e+01,  1.45319424e+01,\n",
              "       -1.71690331e+01, -2.77004059e+02,  2.16983738e+01,  1.11107254e+01,\n",
              "        7.44197416e+00, -1.27972946e+01,  2.26592903e+01, -6.08567543e+01,\n",
              "        1.86379414e+01,  6.96716881e+00, -1.56982079e+01,  5.30572987e+00,\n",
              "        3.56648483e+01,  3.31736832e+01,  3.04539604e+01,  6.29293251e+00,\n",
              "        2.73385620e+01,  4.06596298e+01, -3.27130775e+01, -4.44725990e+00,\n",
              "       -2.21010437e+01,  4.90374565e+00,  2.75500622e+01,  8.62145329e+00,\n",
              "        6.14215851e+00, -9.92536902e-01,  2.91980114e+01, -4.52448349e+01,\n",
              "       -2.07170582e+01,  2.93461370e+00,  1.05208921e+01, -6.29086971e+00,\n",
              "        3.60332394e+00,  1.12618647e+01, -2.06052170e+01, -1.09792595e+01,\n",
              "       -2.49805984e+02, -3.41874199e+01,  4.29432945e+01, -1.21359701e+01,\n",
              "        9.86450100e+00,  1.10048838e+01, -1.82675400e+01,  2.06335392e+01,\n",
              "        1.55032377e+01, -1.85103428e+00,  2.00492687e+01, -2.96386833e+01,\n",
              "        1.65710106e+01, -6.81961727e+00, -7.44183636e+00, -2.91977100e+01,\n",
              "       -1.69628215e+00,  2.89027023e+01,  4.51351833e+00, -1.70994794e+00,\n",
              "        5.34925919e+01,  3.18504715e+00, -3.76354141e+01, -3.09734325e+01,\n",
              "       -4.48237076e+01,  3.78436241e+01,  6.21611071e+00,  6.44620800e+00,\n",
              "        3.18220024e+01,  2.15657272e+01,  2.40848083e+01,  4.16764984e+01,\n",
              "       -4.89803619e+01,  1.08362989e+01, -3.07687721e+01, -1.70170438e+00,\n",
              "       -7.18611956e-01,  5.23042679e+00,  1.58824568e+01,  3.10762539e+01,\n",
              "        1.79877281e+01,  2.38747883e+01, -3.78335266e+01, -1.30926704e+01,\n",
              "       -9.91564751e+00, -1.48288450e+01,  2.20496988e+00, -2.26387709e-01,\n",
              "        8.90744591e+00,  1.71104813e+01,  2.96772423e+01, -2.62704706e+00,\n",
              "        1.59212761e+01, -6.81042004e+00,  1.04790621e+01,  7.54681492e+00,\n",
              "        8.42626190e+00, -2.56797314e-01, -1.93122845e+01, -3.17106647e+01,\n",
              "        2.71964340e+01, -2.61668549e+01,  2.25746307e+01,  1.45464363e+01,\n",
              "        3.19244919e+01, -9.54929543e+00, -5.97243929e+00,  3.01786041e+01,\n",
              "       -1.45979176e+01,  4.46956444e+01,  1.40648260e+01, -1.63110886e+01,\n",
              "        6.68050337e+00, -1.91259480e+01, -2.59454784e+01,  1.82775288e+01,\n",
              "       -1.76079102e+01, -3.55147972e+01, -7.15423727e+00,  3.26713448e+01,\n",
              "       -1.87001743e+01,  9.55431747e+00,  1.23126078e+01, -2.81025677e+01,\n",
              "       -2.77135563e+00,  1.53584414e+01,  8.70773602e+00,  1.68894081e+01,\n",
              "       -1.86237812e+01,  3.62206578e+00,  1.42998829e+01, -5.63827324e+00,\n",
              "        6.67488527e+00, -2.22614980e+00, -3.04327068e+01, -5.73459549e+01,\n",
              "       -2.45654182e+01, -2.35476780e+01,  1.55996561e+00, -1.09115849e+01,\n",
              "       -2.29983616e+01, -3.49158058e+01, -1.29531393e+01,  2.13902702e+01,\n",
              "        2.66235590e+00,  4.87465286e+00,  4.44765930e+01,  4.24344749e+01,\n",
              "       -2.44961472e+01, -2.12447395e+01, -9.80951881e+00, -1.33427944e+01,\n",
              "        1.04232445e+01, -9.21680641e+00,  1.24526100e+01,  5.94417610e+01,\n",
              "       -6.10956907e+00, -9.59260559e+00, -2.99432850e+01,  5.26056004e+00,\n",
              "        3.15173988e+01,  3.91201668e+01, -3.55774193e+01,  4.60234985e+01,\n",
              "       -3.17278938e+01, -6.29657135e+01,  1.24403775e+00, -6.83679628e+00,\n",
              "       -1.76748085e+01, -1.18853941e+01, -2.19551849e+01, -1.13010187e+01,\n",
              "        1.64381695e+01,  1.89908733e+01, -6.86214972e+00, -2.48900056e+00,\n",
              "       -7.32331848e+00,  1.22050791e+01,  1.17103386e+01,  2.46261292e+01,\n",
              "        9.00122261e+00, -3.55039520e+01, -1.37532959e+01,  4.23551979e+01,\n",
              "        2.64246597e+01,  1.67425327e+01,  1.38308382e+01, -1.10022049e+01,\n",
              "       -5.57611799e+00,  5.89017181e+01, -5.52971992e+01,  2.56355801e+01,\n",
              "        7.44835258e-01, -8.25302982e+00,  6.29401827e+00, -3.27921715e+01,\n",
              "       -3.77356033e+01, -5.01501846e+01, -7.87573147e+00,  3.70991745e+01],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sl3JcoHyFStj"
      },
      "source": [
        "##Generate Word2Vec embeddings for training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIEW4Das_iY5",
        "outputId": "eb3ede34-6f04-4a33-e65e-61d6ece8a95b"
      },
      "source": [
        "X_train = [get_word_vectors(doc) for doc in X_train]\n",
        "print(np.shape(X_train))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7769, 300)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "puebpj9jFUmt"
      },
      "source": [
        "##Generate Word2Vec embeddings for testing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4MNhMvlDDP5r",
        "outputId": "4cb8c68a-ec0b-490d-ca22-1af637e51567"
      },
      "source": [
        "X_test = [get_word_vectors(doc) for doc in X_test]\n",
        "print(np.shape(X_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3019, 300)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3AriLLRFtro"
      },
      "source": [
        "#Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5UoWPD8FCN1"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAl2PmBCGI-P"
      },
      "source": [
        "##Fit and Predict model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44HOy5FoF8Ca",
        "outputId": "bec925aa-4bf9-40db-be30-d0df3a0c71cb"
      },
      "source": [
        "lr = OneVsRestClassifier(LogisticRegression(solver='newton-cg'))\n",
        "lr.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OneVsRestClassifier(estimator=LogisticRegression(C=1.0, class_weight=None,\n",
              "                                                 dual=False, fit_intercept=True,\n",
              "                                                 intercept_scaling=1,\n",
              "                                                 l1_ratio=None, max_iter=100,\n",
              "                                                 multi_class='auto',\n",
              "                                                 n_jobs=None, penalty='l2',\n",
              "                                                 random_state=None,\n",
              "                                                 solver='newton-cg', tol=0.0001,\n",
              "                                                 verbose=0, warm_start=False),\n",
              "                    n_jobs=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0k6ZXaogHJT6"
      },
      "source": [
        "y_pred = lr.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bciAwgN-JQbz"
      },
      "source": [
        "##Classification report"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cua5-rEtJOHo",
        "outputId": "fed77f22-8b65-46b7-d4cf-491dca1494a3"
      },
      "source": [
        "print(\"Word2vec Result word on Test\")\n",
        "print(classification_report(y_pred=y_pred , y_true=y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Word2vec Result word on Test\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.91      0.92       719\n",
            "           1       0.78      0.30      0.44        23\n",
            "           2       0.83      0.71      0.77        14\n",
            "           3       0.73      0.63      0.68        30\n",
            "           4       0.67      0.78      0.72        18\n",
            "           5       0.00      0.00      0.00         1\n",
            "           6       0.70      0.78      0.74        18\n",
            "           7       1.00      0.50      0.67         2\n",
            "           8       0.00      0.00      0.00         3\n",
            "           9       0.79      0.93      0.85        28\n",
            "          10       0.82      0.78      0.80        18\n",
            "          11       0.00      0.00      0.00         1\n",
            "          12       0.65      0.79      0.71        56\n",
            "          13       0.69      0.55      0.61        20\n",
            "          14       0.00      0.00      0.00         2\n",
            "          15       0.67      0.64      0.65        28\n",
            "          16       0.00      0.00      0.00         1\n",
            "          17       0.75      0.84      0.79       189\n",
            "          18       0.00      0.00      0.00         1\n",
            "          19       0.54      0.59      0.57        44\n",
            "          20       0.00      0.00      0.00         4\n",
            "          21       0.96      0.98      0.97      1087\n",
            "          22       0.36      0.40      0.38        10\n",
            "          23       0.69      0.65      0.67        17\n",
            "          24       0.89      0.94      0.92        35\n",
            "          25       0.86      0.63      0.73        30\n",
            "          26       0.89      0.84      0.86       149\n",
            "          27       0.00      0.00      0.00         4\n",
            "          28       0.00      0.00      0.00         1\n",
            "          29       0.18      0.40      0.25         5\n",
            "          30       0.75      0.50      0.60         6\n",
            "          31       0.75      0.75      0.75         4\n",
            "          32       1.00      0.43      0.60         7\n",
            "          33       0.00      0.00      0.00         1\n",
            "          34       0.57      0.64      0.60       131\n",
            "          35       0.83      0.83      0.83        12\n",
            "          36       0.42      0.36      0.38        14\n",
            "          37       0.00      0.00      0.00         1\n",
            "          38       0.80      0.76      0.78        21\n",
            "          39       0.00      0.00      0.00         2\n",
            "          40       1.00      0.29      0.44        14\n",
            "          41       0.75      1.00      0.86         3\n",
            "          42       0.00      0.00      0.00         1\n",
            "          43       0.50      0.58      0.54        24\n",
            "          44       1.00      0.50      0.67         6\n",
            "          45       0.56      0.26      0.36        19\n",
            "          46       0.66      0.73      0.70       179\n",
            "          47       0.62      0.74      0.68        34\n",
            "          48       1.00      0.25      0.40         4\n",
            "          49       0.60      0.40      0.48        30\n",
            "          50       0.00      0.00      0.00         1\n",
            "          51       0.00      0.00      0.00         2\n",
            "          52       0.00      0.00      0.00         2\n",
            "          53       1.00      0.33      0.50         6\n",
            "          54       0.56      0.70      0.62        47\n",
            "          55       0.78      0.64      0.70        11\n",
            "          56       0.00      0.00      0.00         1\n",
            "          57       0.67      0.40      0.50        10\n",
            "          58       0.00      0.00      0.00         1\n",
            "          59       0.71      0.42      0.53        12\n",
            "          60       1.00      0.14      0.25         7\n",
            "          61       0.00      0.00      0.00         3\n",
            "          62       0.00      0.00      0.00         3\n",
            "          63       0.00      0.00      0.00         1\n",
            "          64       0.00      0.00      0.00         3\n",
            "          65       0.57      0.44      0.50         9\n",
            "          66       0.81      0.72      0.76        18\n",
            "          67       1.00      0.50      0.67         2\n",
            "          68       0.83      0.42      0.56        24\n",
            "          69       1.00      0.50      0.67        12\n",
            "          70       0.00      0.00      0.00         1\n",
            "          71       0.82      0.67      0.74        89\n",
            "          72       1.00      0.50      0.67         8\n",
            "          73       0.50      0.40      0.44        10\n",
            "          74       0.86      0.46      0.60        13\n",
            "          75       0.71      0.45      0.56        11\n",
            "          76       0.59      0.73      0.65        33\n",
            "          77       0.33      0.18      0.24        11\n",
            "          78       0.84      0.86      0.85        36\n",
            "          79       0.00      0.00      0.00         1\n",
            "          80       0.00      0.00      0.00         2\n",
            "          81       1.00      0.20      0.33         5\n",
            "          82       0.00      0.00      0.00         4\n",
            "          83       1.00      0.58      0.74        12\n",
            "          84       0.53      0.69      0.60       117\n",
            "          85       0.64      0.43      0.52        37\n",
            "          86       0.80      0.79      0.79        71\n",
            "          87       1.00      0.70      0.82        10\n",
            "          88       0.20      0.14      0.17        14\n",
            "          89       0.89      0.62      0.73        13\n",
            "\n",
            "   micro avg       0.82      0.80      0.81      3744\n",
            "   macro avg       0.53      0.41      0.44      3744\n",
            "weighted avg       0.82      0.80      0.80      3744\n",
            " samples avg       0.82      0.85      0.83      3744\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8NIRnzjtJ-yk"
      },
      "source": [
        "#Naive Bayes Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6UBhiRkJjZb"
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.multiclass import OneVsRestClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRRaBg7xLllG"
      },
      "source": [
        "##Fit and Predict model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WltVnWyKKXc8",
        "outputId": "00cecd5d-8ec8-4245-f02a-8b8282a0d8b4"
      },
      "source": [
        "gnb = OneVsRestClassifier(GaussianNB())\n",
        "gnb.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OneVsRestClassifier(estimator=GaussianNB(priors=None, var_smoothing=1e-09),\n",
              "                    n_jobs=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EU6ShkcnKtDc"
      },
      "source": [
        "y_pred_nb = gnb.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPU8Tq9vLg7E"
      },
      "source": [
        "##Classification report"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D__aHyf7K06i",
        "outputId": "8b058d98-8665-45b4-9751-f62213023eb1"
      },
      "source": [
        "print(\"Naive Bayes Classifier Result word on Test\")\n",
        "print(classification_report(y_pred=y_pred_nb, y_true=y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Naive Bayes Classifier Result word on Test\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.34      0.92      0.50       719\n",
            "           1       0.03      0.70      0.05        23\n",
            "           2       0.05      0.86      0.09        14\n",
            "           3       0.04      0.47      0.08        30\n",
            "           4       0.09      0.78      0.17        18\n",
            "           5       0.00      0.00      0.00         1\n",
            "           6       0.02      0.28      0.03        18\n",
            "           7       0.00      0.00      0.00         2\n",
            "           8       0.10      0.67      0.17         3\n",
            "           9       0.03      0.36      0.06        28\n",
            "          10       0.02      0.72      0.04        18\n",
            "          11       0.00      0.00      0.00         1\n",
            "          12       0.07      0.43      0.12        56\n",
            "          13       0.08      0.65      0.15        20\n",
            "          14       0.00      0.00      0.00         2\n",
            "          15       0.12      0.57      0.19        28\n",
            "          16       1.00      1.00      1.00         1\n",
            "          17       0.18      0.43      0.26       189\n",
            "          18       0.00      0.00      0.00         1\n",
            "          19       0.13      0.45      0.21        44\n",
            "          20       0.00      0.25      0.00         4\n",
            "          21       0.48      0.93      0.63      1087\n",
            "          22       0.11      0.40      0.17        10\n",
            "          23       0.02      0.35      0.04        17\n",
            "          24       0.10      0.89      0.18        35\n",
            "          25       0.34      0.77      0.47        30\n",
            "          26       0.18      0.44      0.26       149\n",
            "          27       0.00      0.00      0.00         4\n",
            "          28       0.00      0.00      0.00         1\n",
            "          29       0.01      0.20      0.02         5\n",
            "          30       0.01      0.50      0.01         6\n",
            "          31       0.03      0.50      0.06         4\n",
            "          32       0.11      0.71      0.19         7\n",
            "          33       0.00      0.00      0.00         1\n",
            "          34       0.31      0.40      0.35       131\n",
            "          35       0.03      0.33      0.05        12\n",
            "          36       0.02      0.29      0.03        14\n",
            "          37       0.01      1.00      0.02         1\n",
            "          38       0.09      0.52      0.15        21\n",
            "          39       0.00      0.00      0.00         2\n",
            "          40       0.05      0.57      0.09        14\n",
            "          41       0.01      1.00      0.01         3\n",
            "          42       0.00      0.00      0.00         1\n",
            "          43       0.06      0.50      0.10        24\n",
            "          44       0.50      0.50      0.50         6\n",
            "          45       0.10      0.74      0.17        19\n",
            "          46       0.20      0.34      0.25       179\n",
            "          47       0.11      0.56      0.19        34\n",
            "          48       0.00      0.00      0.00         4\n",
            "          49       0.02      0.27      0.04        30\n",
            "          50       0.00      0.00      0.00         1\n",
            "          51       0.00      0.00      0.00         2\n",
            "          52       0.00      0.00      0.00         2\n",
            "          53       0.03      0.33      0.06         6\n",
            "          54       0.07      0.47      0.12        47\n",
            "          55       0.01      0.73      0.01        11\n",
            "          56       0.00      0.00      0.00         1\n",
            "          57       0.04      0.60      0.08        10\n",
            "          58       0.00      0.00      0.00         1\n",
            "          59       0.08      0.58      0.14        12\n",
            "          60       0.00      0.00      0.00         7\n",
            "          61       1.00      0.33      0.50         3\n",
            "          62       0.00      0.00      0.00         3\n",
            "          63       0.00      0.00      0.00         1\n",
            "          64       0.00      0.00      0.00         3\n",
            "          65       0.05      0.44      0.10         9\n",
            "          66       0.10      0.61      0.17        18\n",
            "          67       0.01      1.00      0.02         2\n",
            "          68       0.08      0.54      0.15        24\n",
            "          69       0.01      0.17      0.01        12\n",
            "          70       0.00      0.00      0.00         1\n",
            "          71       0.34      0.93      0.50        89\n",
            "          72       0.11      0.50      0.17         8\n",
            "          73       0.03      0.50      0.05        10\n",
            "          74       0.05      0.54      0.09        13\n",
            "          75       0.04      0.64      0.07        11\n",
            "          76       0.05      0.48      0.09        33\n",
            "          77       0.02      0.64      0.04        11\n",
            "          78       0.03      0.31      0.06        36\n",
            "          79       0.00      0.00      0.00         1\n",
            "          80       0.00      0.00      0.00         2\n",
            "          81       0.02      0.40      0.04         5\n",
            "          82       0.00      0.25      0.01         4\n",
            "          83       0.01      0.25      0.02        12\n",
            "          84       0.15      0.54      0.24       117\n",
            "          85       0.12      0.73      0.20        37\n",
            "          86       0.10      0.45      0.17        71\n",
            "          87       0.07      0.30      0.12        10\n",
            "          88       0.02      0.36      0.04        14\n",
            "          89       0.03      0.85      0.07        13\n",
            "\n",
            "   micro avg       0.13      0.70      0.22      3744\n",
            "   macro avg       0.09      0.41      0.12      3744\n",
            "weighted avg       0.28      0.70      0.38      3744\n",
            " samples avg       0.31      0.74      0.39      3744\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJi2O2CuLSUV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}